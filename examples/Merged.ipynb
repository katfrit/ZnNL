{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7154d0a8",
   "metadata": {},
   "source": [
    "# Pretraining Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a505abb",
   "metadata": {},
   "source": [
    "## The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f62b3c",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import znnl as nl\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "from jax import random\n",
    "from jax.lib import xla_bridge\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"Using: {xla_bridge.get_backend().platform}\")\n",
    "import copy as cp\n",
    "import jax.numpy as jnp\n",
    "from papyrus.measurements import Loss, Accuracy, NTKEntropy, NTKTrace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9a90b",
   "metadata": {},
   "source": [
    "## The Actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c52138",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = nl.data.MNISTGenerator(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127b8db",
   "metadata": {},
   "source": [
    "## The Data Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63341910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_numbers(data_set: dict, nr_type) -> dict:\n",
    "    \"\"\"\n",
    "    Takes in a data set and returns a filtered data set only consisting of odd or even numbers.\n",
    "    n; block dims: 128x1x1; grid dims\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    data_set : dict\n",
    "            data set to be filtered.\n",
    "    nr_type : integer\n",
    "            For even numbers put 0, for odd numbers put 1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filtered_data_set : dict\n",
    "            filtered data set\n",
    "    \"\"\"\n",
    "    if nr_type == 1:\n",
    "        \n",
    "        # decompose data set into inputs and targets:\n",
    "        inputs = data_set['inputs']\n",
    "        targets = data_set['targets']\n",
    "    \n",
    "        # Get indices of odd numbers using targets:\n",
    "        integer_targets = np.argmax(targets, axis=1)\n",
    "        mod_targets = integer_targets % 2\n",
    "        indices_of_odd_numbers = np.argwhere(mod_targets == 1).squeeze()\n",
    "    \n",
    "        # Take data according to indices: \n",
    "        inputs_odd = inputs[indices_of_odd_numbers]\n",
    "        targets_odd = targets[indices_of_odd_numbers]\n",
    "    \n",
    "        # Construct and return new data set:\n",
    "        return {\"inputs\": inputs_odd, \"targets\": targets_odd}\n",
    "    \n",
    "    if nr_type == 0:\n",
    "\n",
    "        # decompose data set into inputs and targets:\n",
    "        inputs = data_set['inputs']\n",
    "        targets = data_set['targets']\n",
    "    \n",
    "        # Get indices of odd numbers using targets:\n",
    "        integer_targets = np.argmax(targets, axis=1)\n",
    "        mod_targets = integer_targets % 2\n",
    "        indices_of_even_numbers = np.argwhere(mod_targets == 0).squeeze()\n",
    "    \n",
    "        # Take data according to indices: \n",
    "        inputs_even = inputs[indices_of_even_numbers]\n",
    "        targets_even = targets[indices_of_even_numbers]\n",
    "    \n",
    "        # Construct and return new data set:\n",
    "        return {\"inputs\": inputs_even, \"targets\": targets_even}\n",
    "    \n",
    "    else:\n",
    "        return print(\"Please enter correct arguments. See documentation for help.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_subset_of_data(dataset: dict, seed: int, num_samples: int):\n",
    "    \"\"\"\n",
    "    Selects a subset of data given an input dictionary.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    data_set : dict\n",
    "            data set\n",
    "    seed : integer\n",
    "            used to initialize a random number generator\n",
    "    num_samples : integer\n",
    "            Number of samples to be taken from the data set\n",
    "    \"\"\"\n",
    "\n",
    "    # Generates random indices to select samples from the data:\n",
    "    idx = random.randint(random.PRNGKey(seed), shape=(num_samples,), minval=0, maxval=dataset['targets'].shape[0])\n",
    "\n",
    "    # Conerting into a NumPy array:\n",
    "    idx = np.array(idx)\n",
    "\n",
    "    # Filling a new dictionary:\n",
    "    subset = {k: jnp.take(v, idx, axis=0) for k, v in dataset.items()}\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439626d",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model:\n",
    "\n",
    "# Old model:\n",
    "#class pretrained_CNN(nn.Module):\n",
    "#    \"\"\"\n",
    "#    Simple CNN module.\n",
    "#    \"\"\"\n",
    "#\n",
    "#    @nn.compact\n",
    "#    def __call__(self, x):\n",
    "#        x = nn.Conv(features=128, kernel_size=(3, 3))(x)\n",
    "#        x = nn.relu(x)\n",
    "#        x = nn.max_pool(x, window_shape=(3, 3), strides=(2, 2))\n",
    "#        x = nn.Conv(features=128, kernel_size=(3, 3))(x)\n",
    "#        x = nn.relu(x)\n",
    "#        x = nn.max_pool(x, window_shape=(3, 3), strides=(2, 2))\n",
    "#        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "#        x = nn.Dense(features=300)(x)\n",
    "#        x = nn.relu(x)\n",
    "#        x = nn.Dense(10)(x)\n",
    "#\n",
    "#        return x\n",
    "    \n",
    "# New model:\n",
    "class FullyConnectedNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple NN module.\n",
    "    \"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(10)(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a62563",
   "metadata": {},
   "source": [
    "## The Pretraining (Even Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb89bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the optimization algorithm here:\n",
    "production_model = nl.models.FlaxModel(\n",
    "            flax_module=FullyConnectedNetwork(),\n",
    "            optimizer=optax.sgd(learning_rate=0.00005, momentum=0.9),\n",
    "            input_shape=(1, 28, 28, 1),\n",
    "            seed=0\n",
    "        )\n",
    "\n",
    "# To plot the losses, accuracy, etc. we put in recorders:\n",
    "\n",
    "pretrain_recorder_even = nl.training_recording.JaxRecorder( \n",
    "    name=\"pretrain_recorder_even\", \n",
    "    # where to save the data:\n",
    "    storage_path=\".\", \n",
    "    measurements=[\n",
    "        Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "        Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()), \n",
    "    ],\n",
    "    # number of samples to keep in memory before writing to disk:\n",
    "    chunk_size=1e5, \n",
    "    # number of epochs between recording:\n",
    "    update_rate=1\n",
    ")\n",
    "\n",
    "pretest_recorder_even = nl.training_recording.JaxRecorder( \n",
    "    name=\"pretest_recorder_even\", \n",
    "    storage_path=\".\", \n",
    "    measurements=[\n",
    "        Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "        Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()), \n",
    "    ],\n",
    "    chunk_size=1e5, \n",
    "    update_rate=1\n",
    ")\n",
    "\n",
    "pretest_recorder_odd = nl.training_recording.JaxRecorder( \n",
    "    name=\"pretest_recorder_odd\", \n",
    "    storage_path=\".\", \n",
    "    measurements=[\n",
    "        Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "        Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()), \n",
    "    ],\n",
    "    chunk_size=1e5, \n",
    "    update_rate=1\n",
    ")\n",
    "\n",
    "pretrain_recorder_even.instantiate_recorder(data_set=filter_numbers(data_generator.train_ds, 0), model=production_model)\n",
    "pretest_recorder_even.instantiate_recorder(data_set=filter_numbers(data_generator.test_ds, 0), model=production_model)\n",
    "pretest_recorder_odd.instantiate_recorder(data_set=filter_numbers(data_generator.test_ds, 1), model=production_model)\n",
    "\n",
    "# The training strategy:\n",
    "production_pretraining = nl.training_strategies.SimpleTraining(\n",
    "    model=production_model, \n",
    "    loss_fn=nl.loss_functions.CrossEntropyLoss(),\n",
    "    accuracy_fn=nl.accuracy_functions.LabelAccuracy(), \n",
    "    recorders=[pretrain_recorder_even, pretest_recorder_even, pretest_recorder_odd]\n",
    ")\n",
    "\n",
    "# Here the training of the CNN takes place:\n",
    "production_pretraining.train_model(\n",
    "    train_ds=filter_numbers(data_generator.train_ds, 0),\n",
    "    test_ds=filter_numbers(data_generator.test_ds, 0),\n",
    "    batch_size=64,\n",
    "    epochs=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ef906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We gather the recorded losses and plot them over the epochs:\n",
    "pretrain_report_even = pretrain_recorder_even.gather()\n",
    "pretest_report_even = pretest_recorder_even.gather()\n",
    "pretest_report_odd = pretest_recorder_odd.gather()\n",
    "\n",
    "plt.plot(pretrain_report_even[\"loss\"], 'o', mfc='None', label=\"Pretraining with even numbers\")\n",
    "plt.plot(pretest_report_even[\"loss\"], '.', mfc=\"None\", label=\"Testing with even numbers\")\n",
    "plt.plot(pretest_report_odd[\"loss\"], '-', mfc=\"None\", label=\"Testing with odd numbers\")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Here we plot the accuracy:\n",
    "\n",
    "plt.plot(pretrain_report_even[\"accuracy\"], 'o', mfc='None', label=\"Pretraining with even numbers\")\n",
    "plt.plot(pretest_report_even[\"accuracy\"], '.', mfc=\"None\", label=\"Testing with even numbers\")\n",
    "plt.plot(pretest_report_odd[\"accuracy\"], '-', mfc=\"None\", label=\"Testing with odd numbers\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addfdd95",
   "metadata": {},
   "source": [
    "## The Actual Training (Odd Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24deef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recorder_odd = nl.training_recording.JaxRecorder( \n",
    "    name=\"train_recorder_odd\", \n",
    "    storage_path=\".\", \n",
    "    measurements=[\n",
    "        Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "        Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()), \n",
    "    ],\n",
    "    chunk_size=1e5, \n",
    "    update_rate=1\n",
    ")\n",
    "\n",
    "test_recorder_odd = nl.training_recording.JaxRecorder( \n",
    "    name=\"test_recorder_odd\", \n",
    "    storage_path=\".\", \n",
    "    measurements=[\n",
    "        Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "        Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()), \n",
    "    ],\n",
    "    chunk_size=1e5, \n",
    "    update_rate=1\n",
    ")\n",
    "\n",
    "cv_recorder = nl.training_recording.JaxRecorder( \n",
    "    name=\"cv_recorder\", \n",
    "    storage_path=\".\",\n",
    "    measurements=[\n",
    "        Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "        Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()),\n",
    "        NTKEntropy(name=\"ntk_entropy\"), \n",
    "        NTKTrace(name=\"ntk_trace\"),\n",
    "    ],\n",
    "    chunk_size=1e5,\n",
    "    update_rate=1\n",
    ")\n",
    "\n",
    "ntk_computation = nl.analysis.JAXNTKComputation(\n",
    "    apply_fn=production_model.ntk_apply_fn, \n",
    "    batch_size=10,\n",
    ")\n",
    "\n",
    "cv_recorder.instantiate_recorder(\n",
    "    data_set=select_subset_of_data(dataset=filter_numbers(data_generator.test_ds, 1), seed=0, num_samples=100), \n",
    "    model=production_model, \n",
    "    ntk_computation=ntk_computation\n",
    ")\n",
    "\n",
    "train_recorder_odd.instantiate_recorder(data_set=filter_numbers(data_generator.train_ds, 1), model=production_model)\n",
    "test_recorder_odd.instantiate_recorder(data_set=filter_numbers(data_generator.test_ds, 1), model=production_model)\n",
    "\n",
    "\n",
    "# The second training startegy:\n",
    "production_training = nl.training_strategies.SimpleTraining(\n",
    "    model=production_model, \n",
    "    loss_fn=nl.loss_functions.CrossEntropyLoss(),\n",
    "    accuracy_fn=nl.accuracy_functions.LabelAccuracy(), \n",
    "    recorders=[train_recorder_odd, test_recorder_odd, cv_recorder]\n",
    ")\n",
    "\n",
    "# Here the second training of the CNN takes place:\n",
    "production_training.train_model(\n",
    "    train_ds=filter_numbers(data_generator.train_ds, 1),\n",
    "    test_ds=filter_numbers(data_generator.test_ds, 1),\n",
    "    batch_size=64,\n",
    "    epochs=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8985a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We gather the new recorded losses and plot them over the epochs:\n",
    "train_report_odd = train_recorder_odd.gather()\n",
    "test_report_odd = test_recorder_odd.gather()\n",
    "\n",
    "\n",
    "plt.plot(train_report_odd[\"loss\"], 'o', mfc='None', label=\"Training with odd numbers\")\n",
    "plt.plot(test_report_odd[\"loss\"], 'o', mfc='None', label=\"Testing with odd numbers\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Here we plot the new acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_report = cv_recorder.gather()\n",
    "\n",
    "fix, axs = plt.subplots(2, 2, figsize=(8, 6), tight_layout=True)\n",
    "\n",
    "axs[0, 0].plot(cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"Trace\")\n",
    "axs[0, 1].plot(cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"Entropy\")\n",
    "\n",
    "axs[1, 0].plot(np.array(test_report_odd[\"loss\"]), cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"Trace\")\n",
    "axs[1, 1].plot(np.array(test_report_odd[\"loss\"]), cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"Entropy\")\n",
    "\n",
    "axs[1, 0].xaxis.set_inverted(True)\n",
    "axs[1, 1].xaxis.set_inverted(True)\n",
    "\n",
    "axs[0, 0].set_yscale('log')\n",
    "axs[1, 0].set_yscale('log')\n",
    "axs[0, 0].set_xscale('log')\n",
    "axs[0, 1].set_xscale('log')\n",
    "axs[1, 0].set_xscale('log')\n",
    "axs[1, 1].set_xscale('log')\n",
    "\n",
    "axs[0, 0].set_xlabel(\"Epoch\")\n",
    "axs[0, 1].set_xlabel(\"Epoch\")\n",
    "\n",
    "axs[1, 0].set_xlabel(\"Test Loss\")\n",
    "axs[1, 1].set_xlabel(\"Test Loss\")\n",
    "\n",
    "axs[0, 0].set_ylabel(\"Trace\")\n",
    "axs[0, 1].set_ylabel(\"Entropy\")\n",
    "axs[1, 0].set_ylabel(\"Trace\")\n",
    "axs[1, 1].set_ylabel(\"Entropy\")\n",
    "\n",
    "axs[0, 0].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c2a7c",
   "metadata": {},
   "source": [
    "## NOT pretrained Model (Complete MNIST Data Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30958e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_model = cp.deepcopy(FullyConnectedNetwork)\n",
    "\n",
    "\n",
    "# We define the optimization algorithm here:\n",
    "fresh_production_model = nl.models.FlaxModel(\n",
    "            flax_module=fresh_model(),\n",
    "            optimizer=optax.sgd(learning_rate=0.00005, momentum=0.9),\n",
    "            input_shape=(1, 28, 28, 1),\n",
    "            seed=0\n",
    "        )\n",
    "\n",
    "# To plot the losses, we put in a recorder:\n",
    "fresh_train_recorder_odd = nl.training_recording.JaxRecorder( \n",
    "    name=\"fresh_train_recorder_odd\", \n",
    "    storage_path=\".\",\n",
    "    measurements=[\n",
    "        Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "        Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()), \n",
    "    ],\n",
    "    chunk_size=1e5,\n",
    "    update_rate=1\n",
    ")\n",
    "\n",
    "fresh_test_recorder_odd = nl.training_recording.JaxRecorder( \n",
    "    name=\"fresh_test_recorder_odd\", \n",
    "    storage_path=\".\",\n",
    "    measurements=[\n",
    "        Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "        Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()),\n",
    "    ],\n",
    "    chunk_size=1e5,\n",
    "    update_rate=1\n",
    ")\n",
    "\n",
    "\n",
    "fresh_cv_recorder = nl.training_recording.JaxRecorder( \n",
    "    name=\"fresh_cv_recorder\", \n",
    "    storage_path=\".\",\n",
    "    measurements=[\n",
    "        Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "        Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()),\n",
    "        NTKEntropy(name=\"ntk_entropy\"), \n",
    "        NTKTrace(name=\"ntk_trace\"),\n",
    "    ],\n",
    "    chunk_size=1e5,\n",
    "    update_rate=1\n",
    ")\n",
    "\n",
    "ntk_computation = nl.analysis.JAXNTKComputation(\n",
    "    apply_fn=fresh_production_model.ntk_apply_fn, \n",
    "    batch_size=10,\n",
    ")\n",
    "\n",
    "fresh_cv_recorder.instantiate_recorder(\n",
    "    data_set=select_subset_of_data(dataset=filter_numbers(data_generator.test_ds, 1), seed=0, num_samples=100), \n",
    "    model=fresh_production_model, \n",
    "    ntk_computation=ntk_computation\n",
    ")\n",
    "\n",
    "fresh_train_recorder_odd.instantiate_recorder(data_set=filter_numbers(data_generator.train_ds, 1), model=fresh_production_model)\n",
    "fresh_test_recorder_odd.instantiate_recorder(data_set=filter_numbers(data_generator.test_ds, 1), model=fresh_production_model)\n",
    "\n",
    "\n",
    "\n",
    "# The training startegy:\n",
    "fresh_production_training = nl.training_strategies.SimpleTraining(\n",
    "    model=fresh_production_model, \n",
    "    loss_fn=nl.loss_functions.CrossEntropyLoss(),\n",
    "    accuracy_fn=nl.accuracy_functions.LabelAccuracy(), \n",
    "    recorders=[fresh_test_recorder_odd, fresh_train_recorder_odd, fresh_cv_recorder]\n",
    ")\n",
    "\n",
    "# Here the training of the CNN takes place:\n",
    "fresh_production_training.train_model(\n",
    "    train_ds=filter_numbers(data_generator.train_ds, 1),\n",
    "    test_ds=filter_numbers(data_generator.test_ds,1),\n",
    "    batch_size=64,\n",
    "    epochs=2000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the random initialized model\n",
    "\n",
    "# We gather the recorded losses and plot them over the epochs:\n",
    "fresh_train_report_odd = fresh_train_recorder_odd.gather()\n",
    "fresh_test_report_odd = fresh_test_recorder_odd.gather()\n",
    "\n",
    "#cv_recorder4_report = .gather()\n",
    "\n",
    "plt.plot(fresh_train_report_odd[\"loss\"], 'o', mfc='None', label=\"Fresh training with odd numbers\")\n",
    "plt.plot(fresh_test_report_odd[\"loss\"], '.', mfc=\"None\", label=\"Fresh testing with odd numbers\")\n",
    "#plt.plot(cv_recorder4_report[\"ntk_entropy\"], '-', mfc=\"None\", label=\"Entropy\")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Here we plot the new accuracy:\n",
    "plt.plot(fresh_train_report_odd[\"accuracy\"], 'o', mfc='None', label=\"Fresh training with odd numbers\")\n",
    "plt.plot(fresh_test_report_odd[\"accuracy\"], '.', mfc=\"None\", label=\"Fresh testing with odd numbers\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6264db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_cv_report = fresh_cv_recorder.gather()\n",
    "\n",
    "plt.plot(fresh_cv_report[\"ntk_entropy\"], '-', mfc=\"None\", label=\"Entropy\")\n",
    "plt.plot(fresh_cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"Trace\")\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10c0b2",
   "metadata": {},
   "source": [
    "## The Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax1 = axes[0, 0]\n",
    "ax2 = axes[0, 1]\n",
    "ax3 = axes[1, 0]\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "#plt.plot(train_report_odd[\"loss\"], 'o', mfc='None', label=\"Training with odd numbers\")\n",
    "\n",
    "ax1.plot(fresh_test_report_odd[\"loss\"], '.', mfc=\"None\")\n",
    "ax1.plot(test_report_odd[\"loss\"], '.', mfc=\"None\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Test Loss\")\n",
    "ax1.set_title(\"Loss vs. Epochs\")\n",
    "\n",
    "\n",
    "ax2.plot(fresh_test_report_odd[\"accuracy\"], '.', mfc=\"None\", label='fresh NN')\n",
    "ax2.plot(test_report_odd[\"accuracy\"], '.', mfc=\"None\", label=\"pretrained NN\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Test Accuracy\")\n",
    "ax2.set_title(\"Accuracy vs. Epochs\")\n",
    "ax2.legend()\n",
    "\n",
    "ax3.plot(fresh_test_report_odd[\"loss\"], fresh_train_report_odd[\"loss\"], '.', label='fresh NN Test-Loss over train-loss')\n",
    "ax3.plot(test_report_odd[\"loss\"], train_report_odd[\"loss\"], '.', label='pretrained NN Test-Loss over train-loss')\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.set_xlabel(\"Train Loss\")\n",
    "ax3.set_ylabel(\"Test Loss\")\n",
    "ax3.set_title(\"Test-Loss vs. Training-Loss\")\n",
    "\n",
    "ax4.plot(fresh_test_report_odd[\"accuracy\"],fresh_train_report_odd[\"accuracy\"], '.', label='fresh NN test-accuracy over train-loss')\n",
    "ax4.plot(test_report_odd[\"accuracy\"], train_report_odd[\"accuracy\"], '.', label='pretrained NN test-accuracy over train-loss')\n",
    "ax4.set_xlabel(\"Train Accuracy\")\n",
    "ax4.set_ylabel(\"Test Accuracy\")\n",
    "ax4.set_title(\"Test-Accuracy vs. Train-Accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde16ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_report = cv_recorder.gather()\n",
    "fresh_cv_report = fresh_cv_recorder.gather()\n",
    "\n",
    "\n",
    "fix, axs = plt.subplots(2, 2, figsize=(8, 6), tight_layout=True)\n",
    "\n",
    "axs[0, 0].plot(cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"pre-trained\")\n",
    "axs[0, 1].plot(cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"pre-trained\")\n",
    "axs[0, 0].plot(fresh_cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"random\")\n",
    "axs[0, 1].plot(fresh_cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"random\")\n",
    "\n",
    "axs[1, 0].plot(np.array(test_report_odd[\"loss\"]), cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"pre-trained\")\n",
    "axs[1, 1].plot(np.array(test_report_odd[\"loss\"]), cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"pre-trained\")\n",
    "axs[1, 0].plot(np.array(test_report_odd[\"loss\"]), fresh_cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"random\")\n",
    "axs[1, 1].plot(np.array(test_report_odd[\"loss\"]), fresh_cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"random\")\n",
    "\n",
    "axs[1, 0].xaxis.set_inverted(True)\n",
    "axs[1, 1].xaxis.set_inverted(True)\n",
    "\n",
    "axs[0, 0].set_yscale('log')\n",
    "axs[1, 0].set_yscale('log')\n",
    "axs[0, 0].set_xscale('log')\n",
    "axs[0, 1].set_xscale('log')\n",
    "axs[1, 0].set_xscale('log')\n",
    "axs[1, 1].set_xscale('log')\n",
    "\n",
    "axs[0, 0].set_xlabel(\"Epoch\")\n",
    "axs[0, 1].set_xlabel(\"Epoch\")\n",
    "\n",
    "axs[1, 0].set_xlabel(\"Test Loss\")\n",
    "axs[1, 1].set_xlabel(\"Test Loss\")\n",
    "\n",
    "axs[0, 0].set_ylabel(\"Trace\")\n",
    "axs[0, 1].set_ylabel(\"Entropy\")\n",
    "axs[1, 0].set_ylabel(\"Trace\")\n",
    "axs[1, 1].set_ylabel(\"Entropy\")\n",
    "\n",
    "axs[0, 0].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e73c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
