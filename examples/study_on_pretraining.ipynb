{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import znnl as nl\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "from jax import random\n",
    "from jax.lib import xla_bridge\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"Using: {xla_bridge.get_backend().platform}\")\n",
    "import copy as cp\n",
    "import jax.numpy as jnp\n",
    "from papyrus.measurements import Loss, Accuracy, NTKEntropy, NTKTrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_numbers(data_set: dict, nr_type) -> dict:\n",
    "    \"\"\"\n",
    "    Takes in a data set and returns a filtered data set only consisting of odd or even numbers.\n",
    "    n; block dims: 128x1x1; grid dims\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    data_set : dict\n",
    "            data set to be filtered.\n",
    "    nr_type : integer\n",
    "            For even numbers put 0, for odd numbers put 1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filtered_data_set : dict\n",
    "            filtered data set\n",
    "    \"\"\"\n",
    "    if nr_type == 1:\n",
    "        \n",
    "        # decompose data set into inputs and targets:\n",
    "        inputs = data_set['inputs']\n",
    "        targets = data_set['targets']\n",
    "    \n",
    "        # Get indices of odd numbers using targets:\n",
    "        integer_targets = np.argmax(targets, axis=1)\n",
    "        mod_targets = integer_targets % 2\n",
    "        indices_of_odd_numbers = np.argwhere(mod_targets == 1).squeeze()\n",
    "    \n",
    "        # Take data according to indices: \n",
    "        inputs_odd = inputs[indices_of_odd_numbers]\n",
    "        targets_odd = targets[indices_of_odd_numbers]\n",
    "    \n",
    "        # Construct and return new data set:\n",
    "        return {\"inputs\": inputs_odd, \"targets\": targets_odd}\n",
    "    \n",
    "    if nr_type == 0:\n",
    "\n",
    "        # decompose data set into inputs and targets:\n",
    "        inputs = data_set['inputs']\n",
    "        targets = data_set['targets']\n",
    "    \n",
    "        # Get indices of odd numbers using targets:\n",
    "        integer_targets = np.argmax(targets, axis=1)\n",
    "        mod_targets = integer_targets % 2\n",
    "        indices_of_even_numbers = np.argwhere(mod_targets == 0).squeeze()\n",
    "    \n",
    "        # Take data according to indices: \n",
    "        inputs_even = inputs[indices_of_even_numbers]\n",
    "        targets_even = targets[indices_of_even_numbers]\n",
    "    \n",
    "        # Construct and return new data set:\n",
    "        return {\"inputs\": inputs_even, \"targets\": targets_even}\n",
    "    \n",
    "    else:\n",
    "        return print(\"Please enter correct arguments. See documentation for help.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Subsets of Data to shorten computation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_subset_of_data(dataset: dict, seed: int, num_samples: int):\n",
    "    \"\"\"\n",
    "    Selects a subset of data given an input dictionary.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    data_set : dict\n",
    "            data set\n",
    "    seed : integer\n",
    "            used to initialize a random number generator\n",
    "    num_samples : integer\n",
    "            Number of samples to be taken from the data set\n",
    "    \"\"\"\n",
    "\n",
    "    # Generates random indices to select samples from the data:\n",
    "    idx = random.randint(random.PRNGKey(seed), shape=(num_samples,), minval=0, maxval=dataset['targets'].shape[0])\n",
    "\n",
    "    # Conerting into a NumPy array:\n",
    "    idx = np.array(idx)\n",
    "\n",
    "    # Filling a new dictionary:\n",
    "    subset = {k: jnp.take(v, idx, axis=0) for k, v in dataset.items()}\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = nl.data.MNISTGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Function for the Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_MNIST(NN_model, training_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function accepts a neural network model and a dataset, then trains the model using that dataset. It returns plots of ;;;;;;;; and the trained neural network.\n",
    "    SaY STH ABOUT WHERE THE DATA WILL BE STORED\n",
    "    SAY STH ABOUT MNIST DATA\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    NN : Bla Bla\n",
    "            Neural Network model to be trained.\n",
    "    \n",
    "    data_set : dict\n",
    "            Data set to train the neural network model with.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    filtered_data_set : dict\n",
    "            filtered data set\n",
    "    \"\"\"\n",
    "\n",
    "    # The Training Recorders:\n",
    "\n",
    "    train_recorder_even = nl.training_recording.JaxRecorder( \n",
    "        name=\"train_recorder_even\", \n",
    "        storage_path=\".\", \n",
    "        measurements=[\n",
    "            Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "            Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()), \n",
    "        ],\n",
    "        chunk_size=1e5, \n",
    "        update_rate=1\n",
    "    )\n",
    "\n",
    "    train_recorder_odd = nl.training_recording.JaxRecorder( \n",
    "        name=\"train_recorder_odd\", \n",
    "        storage_path=\".\", \n",
    "        measurements=[\n",
    "                Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "                Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()), \n",
    "        ],\n",
    "        chunk_size=1e5, \n",
    "        update_rate=1\n",
    "    )\n",
    "\n",
    "    train_recorder_even.instantiate_recorder(data_set=filter_numbers(data_generator.train_ds, 0), model=NN_model)\n",
    "    train_recorder_odd.instantiate_recorder(data_set=filter_numbers(data_generator.test_ds, 1), model=NN_model)\n",
    "\n",
    "    # The Testing Recorders:\n",
    "\n",
    "    test_recorder_even = nl.training_recording.JaxRecorder( \n",
    "        name=\"test_recorder_even\", \n",
    "        storage_path=\".\",\n",
    "        measurements=[\n",
    "            Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "            Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()),\n",
    "        ],\n",
    "        chunk_size=1e5,\n",
    "        update_rate=1\n",
    "    )\n",
    "    test_recorder_odd = nl.training_recording.JaxRecorder( \n",
    "        name=\"test_recorder_odd\", \n",
    "        storage_path=\".\",\n",
    "        measurements=[\n",
    "            Loss(apply_fn=nl.loss_functions.CrossEntropyLoss()), \n",
    "            Accuracy(apply_fn=nl.accuracy_functions.LabelAccuracy()),\n",
    "        ],\n",
    "        chunk_size=1e5,\n",
    "        update_rate=1\n",
    "    )\n",
    "\n",
    "    test_recorder_even.instantiate_recorder(data_set=filter_numbers(data_generator.train_ds, 0), model=NN_model)\n",
    "    test_recorder_odd.instantiate_recorder(data_set=filter_numbers(data_generator.test_ds, 1), model=NN_model)\n",
    "\n",
    "    # The Collective Variable Recorders:\n",
    "\n",
    "    cv_recorder = nl.training_recording.JaxRecorder( \n",
    "        name=\"cv_recorder\", \n",
    "        storage_path=\".\",\n",
    "        measurements=[\n",
    "            NTKEntropy(name=\"ntk_entropy\"), \n",
    "            NTKTrace(name=\"ntk_trace\"),\n",
    "        ],\n",
    "        chunk_size=1e5,\n",
    "        update_rate=1\n",
    "    )\n",
    "\n",
    "    ntk_computation = nl.analysis.JAXNTKComputation(\n",
    "        apply_fn=NN.ntk_apply_fn, \n",
    "        batch_size=10,\n",
    "    )\n",
    "\n",
    "    cv_recorder.instantiate_recorder(\n",
    "        data_set=select_subset_of_data(dataset=filter_numbers(data_generator.test_ds, 1), seed=0, num_samples=100), \n",
    "        model=NN_model, \n",
    "        ntk_computation=ntk_computation\n",
    "    )\n",
    "\n",
    "    # The training Strategy:\n",
    "\n",
    "    production_pretraining = nl.training_strategies.SimpleTraining(\n",
    "        model=NN_model, \n",
    "        loss_fn=nl.loss_functions.CrossEntropyLoss(),\n",
    "        accuracy_fn=nl.accuracy_functions.LabelAccuracy(), \n",
    "        recorders=[RECORDERS]\n",
    "    )\n",
    "    \n",
    "    # Here the training of the CNN takes place:\n",
    "    production_pretraining.train_model(\n",
    "        train_ds=filter_numbers(data_generator.train_ds, 0),\n",
    "        test_ds=filter_numbers(data_generator.test_ds, 0),\n",
    "        batch_size=64,\n",
    "        epochs=2000,\n",
    "    )\n",
    "\n",
    "    # Gather Reports:\n",
    "\n",
    "    train_report_even = train_recorder_even.gather()\n",
    "    train_report_odd = train_recorder_odd.gather()\n",
    "    test_report_even = test_recorder_even.gather()\n",
    "    test_report_odd= test_recorder_odd.gather()\n",
    "    cv_report = cv_recorder.gather()\n",
    "\n",
    "    # Plot Reports:\n",
    "\n",
    "    fix, axs = plt.subplots(2, 2, figsize=(8, 6), tight_layout=True)\n",
    "\n",
    "    axs[0, 0].plot(cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"pre-trained\")\n",
    "    axs[0, 1].plot(cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"pre-trained\")\n",
    "    axs[0, 0].plot(fresh_cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"random\")\n",
    "    axs[0, 1].plot(fresh_cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"random\")\n",
    "\n",
    "    axs[1, 0].plot(np.array(test_report_odd[\"loss\"]), cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"pre-trained\")\n",
    "    axs[1, 1].plot(np.array(test_report_odd[\"loss\"]), cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"pre-trained\")\n",
    "    axs[1, 0].plot(np.array(test_report_odd[\"loss\"]), fresh_cv_report[\"ntk_trace\"], 'o', mfc=\"None\", label=\"random\")\n",
    "    axs[1, 1].plot(np.array(test_report_odd[\"loss\"]), fresh_cv_report[\"ntk_entropy\"], 'o', mfc=\"None\", label=\"random\")\n",
    "\n",
    "    axs[1, 0].xaxis.set_inverted(True)\n",
    "    axs[1, 1].xaxis.set_inverted(True)\n",
    "\n",
    "    axs[0, 0].set_yscale('log')\n",
    "    axs[1, 0].set_yscale('log')\n",
    "    axs[0, 0].set_xscale('log')\n",
    "    axs[0, 1].set_xscale('log')\n",
    "    axs[1, 0].set_xscale('log')\n",
    "    axs[1, 1].set_xscale('log')\n",
    "\n",
    "    axs[0, 0].set_xlabel(\"Epoch\")\n",
    "    axs[0, 1].set_xlabel(\"Epoch\")\n",
    "\n",
    "    axs[1, 0].set_xlabel(\"Test Loss\")\n",
    "    axs[1, 1].set_xlabel(\"Test Loss\")\n",
    "\n",
    "    axs[0, 0].set_ylabel(\"Trace\")\n",
    "    axs[0, 1].set_ylabel(\"Entropy\")\n",
    "    axs[1, 0].set_ylabel(\"Trace\")\n",
    "    axs[1, 1].set_ylabel(\"Entropy\")\n",
    "\n",
    "    axs[0, 0].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
