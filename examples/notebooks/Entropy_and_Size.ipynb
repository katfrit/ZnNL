{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14c750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samueltovey/miniconda3/envs/zincware/lib/python3.8/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import znrnd\n",
    "\n",
    "import numpy as np\n",
    "import optax\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from neural_tangents import stax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4456f90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 17:18:54.196677: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "data_generator = znrnd.data.MNISTGenerator(ds_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5385874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stax.serial(\n",
    "    stax.Conv(32, (3, 3)),\n",
    "    stax.Relu(),\n",
    "    stax.AvgPool(window_shape=(2, 2), strides=(2, 2)),\n",
    "    stax.Conv(64, (3, 3)),\n",
    "    stax.Relu(),\n",
    "    stax.AvgPool(window_shape=(2, 2), strides=(2, 2)),\n",
    "    stax.Flatten(),\n",
    "    stax.Dense(256),\n",
    "    stax.Relu(),\n",
    "    stax.Dense(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fe0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = {\n",
    "    \"inputs\": data_generator.ds_test[\"image\"],\n",
    "    \"targets\": data_generator.ds_test[\"label\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5b705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_agent = znrnd.agents.RandomAgent(\n",
    "    data_generator=data_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627c122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 500: 100%|██████████████| 500/500 [02:13<00:00,  3.75batch/s, accuracy=0.419, test_loss=4.67]\n",
      "Epoch: 500: 100%|██████████████| 500/500 [02:18<00:00,  3.61batch/s, accuracy=0.487, test_loss=3.07]\n",
      "Epoch: 500: 100%|██████████████| 500/500 [02:19<00:00,  3.58batch/s, accuracy=0.505, test_loss=4.45]\n",
      "Epoch: 500: 100%|██████████████| 500/500 [02:03<00:00,  4.05batch/s, accuracy=0.455, test_loss=6.07]\n",
      "Epoch: 500: 100%|██████████████| 500/500 [02:29<00:00,  3.34batch/s, accuracy=0.548, test_loss=4.01]\n",
      "Epoch: 500: 100%|██████████████| 500/500 [04:00<00:00,  2.08batch/s, accuracy=0.711, test_loss=1.51]\n",
      "Epoch: 500: 100%|██████████████| 500/500 [03:33<00:00,  2.34batch/s, accuracy=0.686, test_loss=3.04]\n",
      "Epoch: 500: 100%|██████████████| 500/500 [03:26<00:00,  2.43batch/s, accuracy=0.631, test_loss=2.28]\n"
     ]
    }
   ],
   "source": [
    "ds_sizes = [20, 50, 100, 150, 200, 300, 500]\n",
    "\n",
    "# Start entropy data sets.\n",
    "start_entropy = []\n",
    "start_entropy_err = []\n",
    "\n",
    "# Final entropy data sets.\n",
    "final_entropy = []\n",
    "final_entropy_err = []\n",
    "\n",
    "# Final min loss\n",
    "min_loss = []\n",
    "min_loss_err = []\n",
    "\n",
    "# Final train metrics\n",
    "min_train_loss = []\n",
    "min_train_loss_err = []\n",
    "\n",
    "# Max acc\n",
    "max_acc = []\n",
    "max_acc_err = []\n",
    "\n",
    "\n",
    "for item in ds_sizes:\n",
    "    entropy_start = []\n",
    "    entropy_end = []\n",
    "    loss = []\n",
    "    acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    for _ in range(5):\n",
    "        # Define a new model.\n",
    "        random_model = znrnd.models.NTModel(\n",
    "            nt_module=model,\n",
    "            optimizer=optax.adam(learning_rate=0.001),\n",
    "            loss_fn=znrnd.loss_functions.CrossEntropyLoss(classes=10, apply_softmax=False),\n",
    "            input_shape=(1, 28, 28, 1),\n",
    "            training_threshold=0.001\n",
    "        )\n",
    "        \n",
    "        # Build the dataset.\n",
    "        random_ds = random_agent.build_dataset(target_size=item)\n",
    "        \n",
    "        # Compute the start entropy.\n",
    "        ntk = random_model.compute_ntk(x_i=random_ds, normalize=False)\n",
    "        entropy_start.append(\n",
    "            znrnd.analysis.EntropyAnalysis(\n",
    "                matrix=ntk[\"empirical\"]\n",
    "            ).compute_von_neumann_entropy()\n",
    "        )\n",
    "        \n",
    "        # Build the dataset.\n",
    "        ds_random = {\n",
    "            \"inputs\": np.take(data_generator.ds_train[\"image\"], random_agent.target_indices, axis=0),\n",
    "            \"targets\": np.take(data_generator.ds_train[\"label\"], random_agent.target_indices, axis=0)\n",
    "        }\n",
    "        \n",
    "        # Train the model.\n",
    "        random_loss, random_acc, training_metrics = random_model.train_model(\n",
    "            train_ds=ds_random, test_ds=test_ds, batch_size=10, epochs=500\n",
    "        )\n",
    "        train_metrics = [item[\"loss\"] for item in training_metrics]\n",
    "        # Compute the final entropy.\n",
    "        ntk = random_model.compute_ntk(x_i=random_ds, normalize=False)\n",
    "        entropy_end.append(\n",
    "            znrnd.analysis.EntropyAnalysis(\n",
    "                matrix=ntk[\"empirical\"]\n",
    "            ).compute_von_neumann_entropy()\n",
    "        )\n",
    "        # Update loss and accuracy arrays\n",
    "        loss.append(np.min(random_loss))\n",
    "        acc.append(np.max(random_acc))\n",
    "        train_loss.append(np.min(train_metrics))\n",
    "        \n",
    "    # Update the stored arrays.\n",
    "    start_entropy.append(np.mean(entropy_start))\n",
    "    start_entropy_err.append(np.std(entropy_start) / np.sqrt(5))\n",
    "    \n",
    "    final_entropy.append(np.mean(entropy_end))\n",
    "    final_entropy_err.append(np.std(entropy_end) / np.sqrt(5))\n",
    "    \n",
    "    min_loss.append(np.mean(loss))\n",
    "    min_loss_err.append(np.std(loss) / np.sqrt(5))\n",
    "    \n",
    "    min_train_loss.append(np.mean(train_loss))\n",
    "    min_loss_err.append(np.std(train_loss) / np.sqrt(5))\n",
    "    \n",
    "    max_acc.append(np.mean(acc))\n",
    "    max_acc_err.append(np.std(acc) / np.sqrt(5))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aaff16",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
