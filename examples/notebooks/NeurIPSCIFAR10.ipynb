{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88cbc36",
   "metadata": {},
   "source": [
    "# NeurIPS CIFAR10 Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59807e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am disabling the GPU here, feel free to comment these lines out if your\n",
    "# Jax installation runs fine on your GPU.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "\n",
    "import znrnd as rnd\n",
    "\n",
    "from neural_tangents import stax\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import optax\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "913e12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = rnd.data.CIFAR10Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d51cadd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stax.serial(\n",
    "    stax.Conv(32, (3, 3)),\n",
    "    stax.Relu(),\n",
    "    stax.AvgPool(window_shape=(2, 2), strides=(2, 2)),\n",
    "    stax.Conv(64, (3, 3)),\n",
    "    stax.Relu(),\n",
    "    stax.AvgPool(window_shape=(2, 2), strides=(2, 2)),\n",
    "    stax.Flatten(),\n",
    "    stax.Dense(256)\n",
    ")\n",
    "model1 = stax.serial(\n",
    "    stax.Conv(32, (3, 3)),\n",
    "    stax.Relu(),\n",
    "    stax.AvgPool((2, 2), (2, 2)),\n",
    "    stax.Conv(64, (3, 3)),\n",
    "    stax.Relu(),\n",
    "    stax.AvgPool((2, 2), (2, 2)),\n",
    "    stax.Flatten(),\n",
    "    stax.Dense(256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce33b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = rnd.models.NTModel(\n",
    "        nt_module=model,\n",
    "        optimizer=optax.sgd(0.001),\n",
    "        loss_fn=znrnd.loss_functions.MeanPowerLoss(order=2),\n",
    "        input_shape=(1, 32, 32, 3),\n",
    "        training_threshold=0.001\n",
    "    )\n",
    "\n",
    "predictor = rnd.models.NTModel(\n",
    "        nt_module=model1,\n",
    "        optimizer=optax.sgd(0.001),\n",
    "        loss_fn=znrnd.loss_functions.MeanPowerLoss(order=2),\n",
    "        input_shape=(1, 32, 32, 3),\n",
    "        training_threshold=0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa542b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = rnd.agents.RND(\n",
    "        point_selector=znrnd.point_selection.GreedySelection(threshold=0.01),\n",
    "        distance_metric=znrnd.distance_metrics.OrderNDifference(order=2),\n",
    "        data_generator=data_generator,\n",
    "        target_network=target,\n",
    "        predictor_network=predictor,\n",
    "        tolerance=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7058b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data_set_size: int, ensembling: bool = False, ensembles: int = 10):\n",
    "    \"\"\"\n",
    "    Run an experiment for a specific datasrndsize.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_set_size : int\n",
    "            Size of the dataset to produce\n",
    "    ensembling : bool (default=False)\n",
    "            If true, the experiment is run several times to produce an error estimate\n",
    "    ensembles : int\n",
    "            Number of ensembles to use in the averaging.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    entropy : dict\n",
    "            A dictionary of the computed entropy:\n",
    "            e.g {\"rnd\": 0.68, \"random\": 0.41, \"approximate_maximum\": 0.84}\n",
    "    eigenvalues : dict\n",
    "            Dictionary of eigenvalues\n",
    "            e.g {\"rnd\": np.array(), \"random\": np.array(), \"approximate_maximum\": np.array()}\n",
    "\n",
    "    \"\"\"\n",
    "    # Turnoff averaging if required.\n",
    "    if not ensembling:\n",
    "        ensembles = 1\n",
    "    \n",
    "    rnd_entropy_arr = []\n",
    "    random_entropy_arr = []\n",
    "    apr_max_entropy_arr = []\n",
    "    \n",
    "    rnd_eig_arr = []\n",
    "    random_eig_arr = []\n",
    "    apr_max_eig_arr = []\n",
    "    \n",
    "    rnd_losses = []\n",
    "    random_losses = []\n",
    "    apr_max_losses = []\n",
    "    \n",
    "    for i in range(ensembles):\n",
    "    \n",
    "        # Define the models\n",
    "        target = rnd.models.NTModel(\n",
    "            nt_module=model,\n",
    "            optimizer=optax.sgd(0.001),\n",
    "            loss_fn=rnd.loss_functions.MeanPowerLoss(order=2),\n",
    "            input_shape=(1, 32, 32, 3),\n",
    "            training_threshold=0.001\n",
    "        )\n",
    "\n",
    "        predictor = rnd.models.NTModel(\n",
    "            nt_module=model1,\n",
    "            optimizer=optax.sgd(0.001),\n",
    "            loss_fn=rnd.loss_functions.MeanPowerLoss(order=2),\n",
    "            input_shape=(1, 32, 32, 3),\n",
    "            training_threshold=0.001\n",
    "        )\n",
    "\n",
    "        # Define the agents for a fresh run.\n",
    "        rnd_agent = rnd.agents.RND(\n",
    "            point_selector=rnd.point_selection.GreedySelection(threshold=0.01),\n",
    "            distance_metric=rnd.distance_metrics.OrderNDifference(order=2),\n",
    "            data_generator=data_generator,\n",
    "            target_network=target,\n",
    "            predictor_network=predictor,\n",
    "            tolerance=15\n",
    "        )\n",
    "        rnd_agent.target_set = []\n",
    "        rnd_agent.target_indices = []\n",
    "        \n",
    "        random_agent = rnd.agents.RandomAgent(data_generator=data_generator)\n",
    "        approximate_max_agent = rnd.agents.ApproximateMaximumEntropy(\n",
    "            target_network=target, \n",
    "            data_generator=data_generator,\n",
    "            samples=10,  # How many sets it produces in the test. Takes the one with max entropy.\n",
    "        )\n",
    "\n",
    "        # Compute the sets\n",
    "        rnd_set = rnd_agent.build_dataset(target_size=data_set_size, visualize=False)\n",
    "        random_set = random_agent.build_dataset(target_size=data_set_size, visualize=False)    \n",
    "        apr_max_set = approximate_max_agent.build_dataset(\n",
    "            target_size=data_set_size, visualize=False\n",
    "        )\n",
    "\n",
    "        # Compute NTK for each set\n",
    "        rnd_ntk = target.compute_ntk(x_i=rnd_set)[\"empirical\"]\n",
    "        random_ntk = target.compute_ntk(x_i=random_set)[\"empirical\"]\n",
    "        apr_max_ntk = target.compute_ntk(x_i=apr_max_set)[\"empirical\"]\n",
    "\n",
    "\n",
    "        # Compute the entropy of each set\n",
    "        rnd_entropy = rnd.analysis.EntropyAnalysis(matrix=rnd_ntk).compute_von_neumann_entropy()\n",
    "        random_entropy = rnd.analysis.EntropyAnalysis(matrix=random_ntk).compute_von_neumann_entropy()\n",
    "        apr_max_entropy = rnd.analysis.EntropyAnalysis(matrix=apr_max_ntk).compute_von_neumann_entropy()\n",
    "\n",
    "\n",
    "        # Compute eigenvalues\n",
    "        rnd_eigval = rnd.analysis.EigenSpaceAnalysis(matrix=rnd_ntk).compute_eigenvalues()\n",
    "        random_eigval = rnd.analysis.EigenSpaceAnalysis(matrix=random_ntk).compute_eigenvalues()\n",
    "        apr_max_eigval = rnd.analysis.EigenSpaceAnalysis(matrix=rnd_ntk).compute_eigenvalues()\n",
    "        \n",
    "        rnd_entropy_arr.append(rnd_entropy)\n",
    "        random_entropy_arr.append(random_entropy)\n",
    "        apr_max_entropy_arr.append(apr_max_entropy)\n",
    "        \n",
    "        rnd_eig_arr.append(rnd_eigval)\n",
    "        random_eig_arr.append(random_eigval)\n",
    "        apr_max_eig_arr.append(apr_max_eigval)\n",
    "        \n",
    "        # Train production model\n",
    "        rnd_production = rnd.models.FlaxModel(\n",
    "            flax_module=CustomModule(),\n",
    "            optimizer=optax.adam(learning_rate=0.001),\n",
    "            loss_fn=rnd.loss_functions.CrossEntropyLoss(classes=10),\n",
    "            input_shape=(1, 32, 32, 3),\n",
    "            training_threshold=0.001\n",
    "        )\n",
    "        \n",
    "        random_production = rnd.models.FlaxModel(\n",
    "            flax_module=CustomModule(),\n",
    "            optimizer=optax.adam(learning_rate=0.001),\n",
    "            loss_fn=rnd.loss_functions.CrossEntropyLoss(classes=10),\n",
    "            input_shape=(1, 32, 32, 3),\n",
    "            training_threshold=0.001\n",
    "        )\n",
    "        \n",
    "        apr_max_production = rnd.models.FlaxModel(\n",
    "            flax_module=CustomModule(),\n",
    "            optimizer=optax.adam(learning_rate=0.001),\n",
    "            loss_fn=rnd.loss_functions.CrossEntropyLoss(classes=10),\n",
    "            input_shape=(1, 32, 32, 3),\n",
    "            training_threshold=0.001\n",
    "        )\n",
    "        \n",
    "        \n",
    "        rnd_training_ds = {\n",
    "            \"inputs\": np.take(data_generator.ds_train[\"image\"], rnd_agent.target_indices, axis=0),\n",
    "            \"targets\": np.take(data_generator.ds_train[\"label\"], rnd_agent.target_indices, axis=0)\n",
    "        }\n",
    "        random_training_ds = {\n",
    "            \"inputs\": np.take(data_generator.ds_train[\"image\"], random_agent.target_indices, axis=0),\n",
    "            \"targets\": np.take(data_generator.ds_train[\"label\"], random_agent.target_indices, axis=0)\n",
    "        }\n",
    "        apr_max_training_ds = {\n",
    "            \"inputs\": np.take(data_generator.ds_train[\"image\"], approximate_max_agent.target_indices, axis=0),\n",
    "            \"targets\": np.take(data_generator.ds_train[\"label\"], approximate_max_agent.target_indices, axis=0)\n",
    "        }\n",
    "        \n",
    "        test_ds = {\n",
    "            \"inputs\": data_generator.ds_test[\"image\"],\n",
    "            \"targets\": data_generator.ds_test[\"label\"]\n",
    "        }\n",
    "        \n",
    "        rnd_losses.append(\n",
    "            rnd_production.train_model(train_ds=rnd_training_ds, test_ds=test_ds)\n",
    "        )\n",
    "        random_losses.append(\n",
    "            random_production.train_model(train_ds=random_training_ds, test_ds=test_ds)\n",
    "        )\n",
    "        apr_max_losses.append(apr_max_production.train_model(train_ds=apr_max_training_ds, test_ds=test_ds))\n",
    "        \n",
    "        \n",
    "        del rnd_agent\n",
    "        del random_agent\n",
    "        del approximate_max_agent\n",
    "    \n",
    "    \n",
    "    # Get mean and uncertainty.\n",
    "    rnd_entropy_arr = np.array(rnd_entropy_arr)\n",
    "    random_entropy_arr = np.array(random_entropy_arr)\n",
    "    apr_max_entropy_arr = np.array(apr_max_entropy_arr)\n",
    "    \n",
    "    rnd_eig_arr = np.array(rnd_eig_arr)\n",
    "    random_eig_arr = np.array(random_eig_arr)\n",
    "    apr_max_eig_arr = np.array(apr_max_eig_arr)\n",
    "    \n",
    "    rnd_losses = np.array(rnd_losses)\n",
    "    random_losses = np.array(random_losses)\n",
    "    apr_max_losses = np.array(apr_max_losses)\n",
    "    \n",
    "    rnd_entropy = np.array(\n",
    "        [np.mean(rnd_entropy_arr), np.std(rnd_entropy_arr) / np.sqrt(ensembles)]\n",
    "    )\n",
    "    random_entropy = np.array(\n",
    "        [np.mean(random_entropy_arr), np.std(random_entropy_arr) / np.sqrt(ensembles)]\n",
    "    )\n",
    "    apr_max_entropy = np.array(\n",
    "        [np.mean(apr_max_entropy_arr), np.std(apr_max_entropy_arr) / np.sqrt(ensembles)]\n",
    "    )\n",
    "\n",
    "    rnd_eigval = np.array(\n",
    "        [np.mean(rnd_eig_arr, axis=0), np.std(rnd_eig_arr, axis=0) / np.sqrt(ensembles)]\n",
    "    )\n",
    "    random_eigval = np.array(\n",
    "        [np.mean(random_eig_arr, axis=0), np.std(random_eig_arr, axis=0) / np.sqrt(ensembles)]\n",
    "    )\n",
    "    apr_max_eigval = np.array(\n",
    "        [np.mean(apr_max_eig_arr, axis=0), np.std(apr_max_eig_arr, axis=0) / np.sqrt(ensembles)]\n",
    "    )\n",
    "    \n",
    "    rnd_loss = np.array(\n",
    "        [np.mean(rnd_losses, axis=0), np.std(rnd_losses, axis=0) / np.sqrt(ensembles)]\n",
    "    )\n",
    "    random_loss = np.array(\n",
    "        [np.mean(random_losses, axis=0), np.std(random_losses, axis=0) / np.sqrt(ensembles)]\n",
    "    )\n",
    "    apr_max_loss = np.array(\n",
    "        [np.mean(apr_max_losses, axis=0), np.std(apr_max_losses, axis=0) / np.sqrt(ensembles)]\n",
    "    )\n",
    "    \n",
    "    entropy = {\"rnd\": rnd_entropy, \"random\": random_entropy, \"approximate_maximum\": apr_max_entropy}\n",
    "    eigenvalues = {\"rnd\": rnd_eigval, \"random\": random_eigval, \"approximate_maximum\": apr_max_eigval}\n",
    "    losses = {\"rnd\": rnd_loss, \"random\": random_loss, \"approximate_maximum\": apr_max_loss}\n",
    "    \n",
    "    return entropy, eigenvalues, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2992777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100: 100%|████████████████████████████████| 100/100 [00:03<00:00, 29.18batch/s, test_loss=60]\n",
      "Epoch: 110: 100%|████████████████████████████| 110/110 [00:03<00:00, 29.47batch/s, test_loss=0.0248]\n",
      "Epoch: 121: 100%|███████████████████████████| 121/121 [00:04<00:00, 28.89batch/s, test_loss=5.35e-6]\n",
      "/tikhome/stovey/miniconda3/envs/zincware/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n",
      "/tikhome/stovey/miniconda3/envs/zincware/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n",
      "/tikhome/stovey/miniconda3/envs/zincware/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n",
      "Epoch: 100: 100%|██████████████████████████████| 100/100 [00:06<00:00, 15.51batch/s, test_loss=94.7]\n",
      "Epoch: 110: 100%|██████████████████████████████| 110/110 [00:07<00:00, 14.79batch/s, test_loss=6.16]\n",
      "Epoch: 121: 100%|█████████████████████████████| 121/121 [00:07<00:00, 15.44batch/s, test_loss=0.298]\n",
      "Epoch: 133: 100%|████████████████████████████| 133/133 [00:08<00:00, 15.25batch/s, test_loss=0.0116]\n",
      "Epoch: 146: 100%|██████████████████████████| 146/146 [00:09<00:00, 15.19batch/s, test_loss=0.000346]\n",
      "/tikhome/stovey/miniconda3/envs/zincware/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n",
      "Epoch: 100: 100%|██████████████████████████████| 100/100 [00:09<00:00, 10.89batch/s, test_loss=90.6]\n",
      "Epoch: 110: 100%|██████████████████████████████| 110/110 [00:10<00:00, 10.71batch/s, test_loss=12.2]\n",
      "Epoch: 121: 100%|██████████████████████████████| 121/121 [00:11<00:00, 10.69batch/s, test_loss=1.45]\n",
      "Epoch: 133: 100%|█████████████████████████████| 133/133 [00:12<00:00, 10.76batch/s, test_loss=0.149]\n",
      "Epoch: 146: 100%|█████████████████████████████| 146/146 [00:13<00:00, 10.65batch/s, test_loss=0.013]\n",
      "Epoch: 160: 100%|██████████████████████████| 160/160 [00:15<00:00, 10.04batch/s, test_loss=0.000952]\n",
      "/tikhome/stovey/miniconda3/envs/zincware/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RND agent report\n",
      "----------------\n",
      "Run time:  3.42 m\n",
      "Size of point cloud: 500\n",
      "Number of points chosen: 3\n",
      "Seed points: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tikhome/stovey/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/_src/ops/scatter.py:114: ComplexWarning:\n",
      "\n",
      "Casting complex values to real discards the imaginary part\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129 387 351]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "convolution requires lhs and rhs ndim to be equal, got 5 and 4.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensembling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensembles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(data_set_size, ensembling, ensembles)\u001b[0m\n\u001b[1;32m     86\u001b[0m rnd_ntk \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcompute_ntk(x_i\u001b[38;5;241m=\u001b[39mrnd_set)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempirical\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     87\u001b[0m random_ntk \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcompute_ntk(x_i\u001b[38;5;241m=\u001b[39mrandom_set)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempirical\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 88\u001b[0m apr_max_ntk \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_ntk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapr_max_set\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempirical\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Compute the entropy of each set\u001b[39;00m\n\u001b[1;32m     92\u001b[0m rnd_entropy \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39manalysis\u001b[38;5;241m.\u001b[39mEntropyAnalysis(matrix\u001b[38;5;241m=\u001b[39mrnd_ntk)\u001b[38;5;241m.\u001b[39mcompute_von_neumann_entropy()\n",
      "File \u001b[0;32m~/work/Repositories/ZINCWARECODE/ZnRND/znrnd/core/models/nt_model.py:151\u001b[0m, in \u001b[0;36mNTModel.compute_ntk\u001b[0;34m(self, x_i, x_j, normalize)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_j \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m x_i\n\u001b[0;32m--> 151\u001b[0m empirical_ntk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempirical_ntk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m infinite_ntk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_fn(x_i, x_j, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mntk\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/neural_tangents/_src/empirical.py:735\u001b[0m, in \u001b[0;36m_direct_ntk_fn.<locals>.ntk_fn\u001b[0;34m(x1, x2, params, **apply_fn_kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m\"\"\"Computes a single sample of the empirical NTK (jacobian outer product).\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;124;03m  All other axes are present twice.\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    734\u001b[0m kwargs1, kwargs2 \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39msplit_kwargs(apply_fn_kwargs, x1, x2)\n\u001b[0;32m--> 735\u001b[0m fx1 \u001b[38;5;241m=\u001b[39m \u001b[43meval_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m x_axis, fx_axis, kw_axes \u001b[38;5;241m=\u001b[39m _canonicalize_axes(vmap_axes, x1, fx1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs1)\n\u001b[1;32m    738\u001b[0m keys \u001b[38;5;241m=\u001b[39m apply_fn_kwargs\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/_src/api.py:2927\u001b[0m, in \u001b[0;36meval_shape\u001b[0;34m(fun, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2925\u001b[0m wrapped_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(lu\u001b[38;5;241m.\u001b[39mwrap_init(fun), in_tree)\n\u001b[1;32m   2926\u001b[0m debug_info \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mdebug_info(fun, in_tree, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2927\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabstract_eval_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_fun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2928\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshaped_abstractify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2929\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2930\u001b[0m out \u001b[38;5;241m=\u001b[39m [ShapeDtypeStruct(x\u001b[38;5;241m.\u001b[39mshape, x\u001b[38;5;241m.\u001b[39mdtype, x\u001b[38;5;241m.\u001b[39mnamed_shape) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out]\n\u001b[1;32m   2931\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out)\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/interpreters/partial_eval.py:514\u001b[0m, in \u001b[0;36mabstract_eval_fun\u001b[0;34m(fun, debug_info, *avals, **params)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mabstract_eval_fun\u001b[39m(fun, \u001b[38;5;241m*\u001b[39mavals, debug_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m--> 514\u001b[0m   _, avals_out, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_to_jaxpr_dynamic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(aval, AbstractValue) \u001b[38;5;28;01mfor\u001b[39;00m aval \u001b[38;5;129;01min\u001b[39;00m avals_out)\n\u001b[1;32m    517\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m avals_out\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/_src/profiler.py:206\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    205\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/interpreters/partial_eval.py:1738\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[0;34m(fun, in_avals, debug_info, keep_inputs)\u001b[0m\n\u001b[1;32m   1736\u001b[0m   main\u001b[38;5;241m.\u001b[39mdebug_info \u001b[38;5;241m=\u001b[39m debug_info  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1737\u001b[0m   main\u001b[38;5;241m.\u001b[39mjaxpr_stack \u001b[38;5;241m=\u001b[39m ()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1738\u001b[0m   jaxpr, out_avals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_to_subjaxpr_dynamic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_avals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1740\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m main, fun\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jaxpr, out_avals, consts\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/interpreters/partial_eval.py:1775\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[0;34m(fun, main, in_avals, keep_inputs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m in_tracers \u001b[38;5;241m=\u001b[39m _avals_to_tracers(trace, in_avals)\n\u001b[1;32m   1774\u001b[0m in_tracers_ \u001b[38;5;241m=\u001b[39m [t \u001b[38;5;28;01mfor\u001b[39;00m t, keep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(in_tracers, keep_inputs) \u001b[38;5;28;01mif\u001b[39;00m keep]\n\u001b[0;32m-> 1775\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1776\u001b[0m out_tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mfull_raise, ans)\n\u001b[1;32m   1777\u001b[0m jaxpr, consts \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mto_jaxpr(out_tracers)\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/linear_util.py:166\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    169\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/linear_util.py:166\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    169\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/example_libraries/stax.py:310\u001b[0m, in \u001b[0;36mserial.<locals>.apply_fun\u001b[0;34m(params, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m rngs \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(rng, nlayers) \u001b[38;5;28;01mif\u001b[39;00m rng \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m nlayers\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fun, param, rng \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(apply_funs, params, rngs):\n\u001b[0;32m--> 310\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/neural_tangents/_src/stax/requirements.py:188\u001b[0m, in \u001b[0;36msupports_masking.<locals>.supports_masking.<locals>.layer_with_masking.<locals>.apply_fn_with_masking\u001b[0;34m(params, inputs, mask_constant, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m inputs \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mnt_tree_fn()(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mmasked_value)(masked_inputs)\n\u001b[1;32m    186\u001b[0m mask \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mnt_tree_fn()(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mmask)(masked_inputs)\n\u001b[0;32m--> 188\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mapply_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m outputs_mask \u001b[38;5;241m=\u001b[39m mask_fn(mask,\n\u001b[1;32m    190\u001b[0m                        inputs\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    191\u001b[0m                        \u001b[38;5;28;01melse\u001b[39;00m [i\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs])\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/neural_tangents/_src/stax/linear.py:1162\u001b[0m, in \u001b[0;36m_Conv.<locals>.apply_fn\u001b[0;34m(params, inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1157\u001b[0m   spatial_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(lhs_spec\u001b[38;5;241m.\u001b[39mindex(c)\n\u001b[1;32m   1158\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m rhs_spec \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1159\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m _same_pad_for_filter_shape(inputs, filter_shape, strides,\n\u001b[1;32m   1160\u001b[0m                                       spatial_axes)\n\u001b[0;32m-> 1162\u001b[0m res \u001b[38;5;241m=\u001b[39m norm \u001b[38;5;241m*\u001b[39m \u001b[43mlax_conv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapply_padding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimension_numbers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m Padding\u001b[38;5;241m.\u001b[39mCIRCULAR \u001b[38;5;129;01mand\u001b[39;00m transpose:\n\u001b[1;32m   1170\u001b[0m   out_shape \u001b[38;5;241m=\u001b[39m eval_shape(\u001b[38;5;28;01mlambda\u001b[39;00m x: lax\u001b[38;5;241m.\u001b[39mconv_transpose(\n\u001b[1;32m   1171\u001b[0m       lhs\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m   1172\u001b[0m       rhs\u001b[38;5;241m=\u001b[39mW,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1175\u001b[0m       dimension_numbers\u001b[38;5;241m=\u001b[39mdimension_numbers\n\u001b[1;32m   1176\u001b[0m   ), inputs)\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/_src/lax/convolution.py:130\u001b[0m, in \u001b[0;36mconv_general_dilated\u001b[0;34m(lhs, rhs, window_strides, padding, lhs_dilation, rhs_dilation, dimension_numbers, feature_group_count, batch_group_count, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconv_general_dilated\u001b[39m(\n\u001b[1;32m     60\u001b[0m   lhs: Array, rhs: Array, window_strides: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     61\u001b[0m   padding: Union[\u001b[38;5;28mstr\u001b[39m, Sequence[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m   precision: lax\u001b[38;5;241m.\u001b[39mPrecisionLike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m   preferred_element_type: Optional[DType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;124;03m\"\"\"General n-dimensional convolution operator, with optional dilation.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m  Wraps XLA's `Conv\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m  'NCHW')`` (for a 2D convolution).\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m   dnums \u001b[38;5;241m=\u001b[39m \u001b[43mconv_dimension_numbers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension_numbers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m lhs_dilation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     lhs_dilation \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m (lhs\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/zincware/lib/python3.9/site-packages/jax/_src/lax/convolution.py:887\u001b[0m, in \u001b[0;36mconv_dimension_numbers\u001b[0;34m(lhs_shape, rhs_shape, dimension_numbers)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lhs_shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rhs_shape):\n\u001b[1;32m    886\u001b[0m   msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvolution requires lhs and rhs ndim to be equal, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 887\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(lhs_shape), \u001b[38;5;28mlen\u001b[39m(rhs_shape)))\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dimension_numbers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   iota \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lhs_shape)))\n",
      "\u001b[0;31mTypeError\u001b[0m: convolution requires lhs and rhs ndim to be equal, got 5 and 4."
     ]
    }
   ],
   "source": [
    "run_experiment(3, ensembling=True, ensembles=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08feb460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
