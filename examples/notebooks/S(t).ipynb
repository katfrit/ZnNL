{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "432499fb",
   "metadata": {},
   "source": [
    "# S(t)\n",
    "\n",
    "Measure the epoch dependence of the entropy of the NTK.\n",
    "\n",
    "### Experiment\n",
    "Perform RND with a model and select N points. Train the model on these N points and use the parameters of the trained model to perform NTK again and see if the points change. Along the way, check the entropy of the updated NTK and see how it has been effected by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923e44f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samueltovey/miniconda3/envs/zincware/lib/python3.8/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "\n",
    "import znrnd as rnd\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import optax\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from neural_tangents import stax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9847f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 17:22:27.580929: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "data_generator = rnd.data.MNISTGenerator(ds_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a09133",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stax.serial(\n",
    "    stax.Conv(32, (3, 3)),\n",
    "    stax.Relu(),\n",
    "    stax.AvgPool(window_shape=(2, 2), strides=(2, 2)),\n",
    "    stax.Conv(64, (3, 3)),\n",
    "    stax.Relu(),\n",
    "    stax.AvgPool(window_shape=(2, 2), strides=(2, 2)),\n",
    "    stax.Flatten(),\n",
    "    stax.Dense(256),\n",
    "    stax.Relu(),\n",
    "    stax.Dense(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1ae49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_model = rnd.models.NTModel(\n",
    "        nt_module=model,\n",
    "        optimizer=optax.adam(learning_rate=0.001),\n",
    "        loss_fn=rnd.loss_functions.CrossEntropyLoss(classes=10, apply_softmax=False),\n",
    "        input_shape=(1, 28, 28, 1),\n",
    "        training_threshold=0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf91ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = {\n",
    "    \"inputs\": data_generator.ds_train[\"image\"],\n",
    "    \"targets\": data_generator.ds_train[\"label\"]\n",
    "}\n",
    "test_ds = {\n",
    "    \"inputs\": data_generator.ds_test[\"image\"],\n",
    "    \"targets\": data_generator.ds_test[\"label\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e772422",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|████████████████████| 1/1 [00:03<00:00,  3.30s/batch, accuracy=0.178, test_loss=2.24]\n",
      "Epoch: 1: 100%|████████████████████| 1/1 [00:01<00:00,  1.13s/batch, accuracy=0.424, test_loss=2.12]\n",
      "Epoch: 1: 100%|████████████████████| 1/1 [00:01<00:00,  1.14s/batch, accuracy=0.627, test_loss=1.91]\n",
      "Epoch: 1: 100%|█████████████████████| 1/1 [00:01<00:00,  1.90s/batch, accuracy=0.73, test_loss=1.59]\n",
      "Epoch: 1: 100%|█████████████████████| 1/1 [00:01<00:00,  1.17s/batch, accuracy=0.78, test_loss=1.22]\n",
      "Epoch: 1: 100%|███████████████████| 1/1 [00:01<00:00,  1.94s/batch, accuracy=0.813, test_loss=0.925]\n",
      "Epoch: 1: 100%|███████████████████| 1/1 [00:01<00:00,  2.00s/batch, accuracy=0.841, test_loss=0.739]\n",
      "Epoch: 1: 100%|███████████████████| 1/1 [00:01<00:00,  1.99s/batch, accuracy=0.851, test_loss=0.627]\n",
      "Epoch: 1: 100%|███████████████████| 1/1 [00:03<00:00,  3.28s/batch, accuracy=0.862, test_loss=0.557]\n",
      "Epoch: 1: 100%|████████████████████| 1/1 [00:02<00:00,  2.15s/batch, accuracy=0.868, test_loss=0.51]\n",
      "Epoch: 1: 100%|███████████████████| 1/1 [00:03<00:00,  3.14s/batch, accuracy=0.878, test_loss=0.477]\n"
     ]
    }
   ],
   "source": [
    "entropy_data = {\n",
    "    \"5\": {\"infinite\": [], \"empirical\": []}, \n",
    "    \"10\": {\"infinite\": [], \"empirical\": []},\n",
    "    \"15\": {\"infinite\": [], \"empirical\": []},\n",
    "    \"20\": {\"infinite\": [], \"empirical\": []},\n",
    "    \"25\": {\"infinite\": [], \"empirical\": []},\n",
    "    \"30\": {\"infinite\": [], \"empirical\": []},\n",
    "    \"35\": {\"infinite\": [], \"empirical\": []},\n",
    "    \"40\": {\"infinite\": [], \"empirical\": []},\n",
    "    \"50\": {\"infinite\": [], \"empirical\": []},\n",
    "    \"100\": {\"infinite\": [], \"empirical\": []},\n",
    "}\n",
    "subsets = [50, 100] # [5, 10, 15, 20, 25, 30, 35, 40, 50, 100]\n",
    "metrics_array = []\n",
    "\n",
    "for _ in range(100):\n",
    "    for item in subsets:\n",
    "        data_subset = data_generator.ds_train[\"image\"][:item]\n",
    "        ntk = production_model.compute_ntk(\n",
    "            data_subset,\n",
    "            normalize=True\n",
    "        )\n",
    "        entropy_inifinite = rnd.analysis.EntropyAnalysis(\n",
    "            ntk[\"infinite\"]\n",
    "        ).compute_von_neumann_entropy(\n",
    "            normalize=False\n",
    "        )\n",
    "        entropy_empirical = rnd.analysis.EntropyAnalysis(\n",
    "            ntk[\"empirical\"]\n",
    "        ).compute_von_neumann_entropy(\n",
    "            normalize=False\n",
    "        )\n",
    "        entropy_data[str(item)][\"infinite\"].append(entropy_inifinite)\n",
    "        entropy_data[str(item)][\"empirical\"].append(entropy_empirical)\n",
    "        \n",
    "    metrics_array.append(production_model.train_model(\n",
    "        train_ds=train_ds, test_ds=test_ds, batch_size=32, epochs=1\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_arr = [item[\"accuracy\"] for item in metrics_array]\n",
    "loss_arr = [item[\"loss\"] for item in metrics_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54176188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colours = [\"red\", \"blue\", \"green\"]\n",
    "scale = [np.log(5), np.log(10), np.log(30)]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for i, item in enumerate(entropy_data):\n",
    "    ax.plot(entropy_data[item][\"empirical\"], label=item)\n",
    "#     ax.plot(entropy_data[item][\"infinite\"]), '-', c=colours[i])\n",
    "\n",
    "ax2.plot(acc_arr, '.')\n",
    "# plt.yscale(\"log\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax.set_ylabel(\"Total Entropy\")\n",
    "plt.savefig(\"Entropy_vs_Training.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dccdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    subsets, \n",
    "    [entropy_data[item][\"empirical\"][-1] for item in entropy_data],\n",
    "    'o',\n",
    "    label=\"empirical\"\n",
    ")\n",
    "plt.plot(\n",
    "    subsets, \n",
    "    [entropy_data[item][\"infinite\"][-1] for item in entropy_data],\n",
    "    'o',\n",
    "    label=\"inifinite\"\n",
    ")\n",
    "plt.xlabel(\"Subset size\")\n",
    "plt.ylabel(\"Final entropy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Final_Entropy_Subsets.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_arr, entropy_data[\"100\"][\"empirical\"], '.')\n",
    "plt.plot(acc_arr, entropy_data[\"50\"][\"empirical\"], '.')\n",
    "plt.plot(acc_arr, entropy_data[\"10\"][\"empirical\"], '.')\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Empirical Entropy\")\n",
    "plt.savefig(\"Entropy_vs_Accuracy.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39df75a",
   "metadata": {},
   "source": [
    "### Information transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9685227",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_array = []\n",
    "for value in entropy_data.values():\n",
    "    data = value[\"empirical\"][0] - value[\"empirical\"][-1]\n",
    "    plot_array.append(data)\n",
    "    \n",
    "plt.plot(subsets, plot_array, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd6eb4",
   "metadata": {},
   "source": [
    "### Area under the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_data = []\n",
    "\n",
    "for value in entropy_data.values():\n",
    "    integral = integrate.trapz(value[\"empirical\"])\n",
    "    integral_data.append(integral)\n",
    "    \n",
    "plt.plot(subsets, integral_data, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061f7b9",
   "metadata": {},
   "source": [
    "## Accuracy vs Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2ec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/S.Tovey/miniconda3/envs/zincware/lib/python3.8/site-packages/jax/_src/tree_util.py:188: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.\n",
      "  warnings.warn('jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() '\n",
      "/home/s/S.Tovey/miniconda3/envs/zincware/lib/python3.8/site-packages/jax/_src/tree_util.py:188: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.\n",
      "  warnings.warn('jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() '\n",
      "Epoch: 200: 100%|██████████████| 200/200 [01:20<00:00,  2.48batch/s, accuracy=0.438, test_loss=2.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': {'entropy': [DeviceArray(1.4299815-0.j, dtype=complex64), DeviceArray(1.0649279-0.j, dtype=complex64)], 'model': {'accuracy': 0.43800002336502075, 'loss': 2.549513816833496}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200: 100%|██████████████| 200/200 [01:29<00:00,  2.23batch/s, accuracy=0.528, test_loss=2.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': {'entropy': [DeviceArray(1.4299815-0.j, dtype=complex64), DeviceArray(1.0649279-0.j, dtype=complex64)], 'model': {'accuracy': 0.43800002336502075, 'loss': 2.549513816833496}}, '20': {'entropy': [DeviceArray(1.6265097-0.j, dtype=complex64), DeviceArray(1.2852912-0.j, dtype=complex64)], 'model': {'accuracy': 0.527999997138977, 'loss': 2.0837535858154297}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200: 100%|██████████████| 200/200 [01:42<00:00,  1.96batch/s, accuracy=0.574, test_loss=2.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': {'entropy': [DeviceArray(1.4299815-0.j, dtype=complex64), DeviceArray(1.0649279-0.j, dtype=complex64)], 'model': {'accuracy': 0.43800002336502075, 'loss': 2.549513816833496}}, '20': {'entropy': [DeviceArray(1.6265097-0.j, dtype=complex64), DeviceArray(1.2852912-0.j, dtype=complex64)], 'model': {'accuracy': 0.527999997138977, 'loss': 2.0837535858154297}}, '30': {'entropy': [DeviceArray(1.7681414-0.j, dtype=complex64), DeviceArray(1.2330437-0.j, dtype=complex64)], 'model': {'accuracy': 0.5740000009536743, 'loss': 2.213181972503662}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200: 100%|███████████████| 200/200 [02:13<00:00,  1.49batch/s, accuracy=0.735, test_loss=2.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': {'entropy': [DeviceArray(1.4299815-0.j, dtype=complex64), DeviceArray(1.0649279-0.j, dtype=complex64)], 'model': {'accuracy': 0.43800002336502075, 'loss': 2.549513816833496}}, '20': {'entropy': [DeviceArray(1.6265097-0.j, dtype=complex64), DeviceArray(1.2852912-0.j, dtype=complex64)], 'model': {'accuracy': 0.527999997138977, 'loss': 2.0837535858154297}}, '30': {'entropy': [DeviceArray(1.7681414-0.j, dtype=complex64), DeviceArray(1.2330437-0.j, dtype=complex64)], 'model': {'accuracy': 0.5740000009536743, 'loss': 2.213181972503662}}, '50': {'entropy': [DeviceArray(1.9276254-0.j, dtype=complex64), DeviceArray(1.2277381-0.j, dtype=complex64)], 'model': {'accuracy': 0.7350000143051147, 'loss': 2.4009249210357666}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200: 100%|██████████████| 200/200 [03:27<00:00,  1.04s/batch, accuracy=0.801, test_loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': {'entropy': [DeviceArray(1.4299815-0.j, dtype=complex64), DeviceArray(1.0649279-0.j, dtype=complex64)], 'model': {'accuracy': 0.43800002336502075, 'loss': 2.549513816833496}}, '20': {'entropy': [DeviceArray(1.6265097-0.j, dtype=complex64), DeviceArray(1.2852912-0.j, dtype=complex64)], 'model': {'accuracy': 0.527999997138977, 'loss': 2.0837535858154297}}, '30': {'entropy': [DeviceArray(1.7681414-0.j, dtype=complex64), DeviceArray(1.2330437-0.j, dtype=complex64)], 'model': {'accuracy': 0.5740000009536743, 'loss': 2.213181972503662}}, '50': {'entropy': [DeviceArray(1.9276254-0.j, dtype=complex64), DeviceArray(1.2277381-0.j, dtype=complex64)], 'model': {'accuracy': 0.7350000143051147, 'loss': 2.4009249210357666}}, '100': {'entropy': [DeviceArray(2.2563639-0.j, dtype=complex64), DeviceArray(1.3267068-0.j, dtype=complex64)], 'model': {'accuracy': 0.8010000586509705, 'loss': 1.0252071619033813}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200: 100%|█████████████| 200/200 [05:47<00:00,  1.74s/batch, accuracy=0.858, test_loss=0.953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': {'entropy': [DeviceArray(1.4299815-0.j, dtype=complex64), DeviceArray(1.0649279-0.j, dtype=complex64)], 'model': {'accuracy': 0.43800002336502075, 'loss': 2.549513816833496}}, '20': {'entropy': [DeviceArray(1.6265097-0.j, dtype=complex64), DeviceArray(1.2852912-0.j, dtype=complex64)], 'model': {'accuracy': 0.527999997138977, 'loss': 2.0837535858154297}}, '30': {'entropy': [DeviceArray(1.7681414-0.j, dtype=complex64), DeviceArray(1.2330437-0.j, dtype=complex64)], 'model': {'accuracy': 0.5740000009536743, 'loss': 2.213181972503662}}, '50': {'entropy': [DeviceArray(1.9276254-0.j, dtype=complex64), DeviceArray(1.2277381-0.j, dtype=complex64)], 'model': {'accuracy': 0.7350000143051147, 'loss': 2.4009249210357666}}, '100': {'entropy': [DeviceArray(2.2563639-0.j, dtype=complex64), DeviceArray(1.3267068-0.j, dtype=complex64)], 'model': {'accuracy': 0.8010000586509705, 'loss': 1.0252071619033813}}, '200': {'entropy': [DeviceArray(2.3037105-0.j, dtype=complex64), DeviceArray(1.3987174-0.j, dtype=complex64)], 'model': {'accuracy': 0.8580000400543213, 'loss': 0.9532071948051453}}}\n"
     ]
    }
   ],
   "source": [
    "subsets = [10, 20, 30, 50, 100, 200, 500, 800]\n",
    "metrics_dict = {}\n",
    "\n",
    "for item in subsets:\n",
    "    data_subset = data_generator.ds_train[\"image\"][:item]\n",
    "    \n",
    "    production_model = rnd.models.NTModel(\n",
    "        nt_module=model,\n",
    "        optimizer=optax.adam(learning_rate=0.001),\n",
    "        loss_fn=rnd.loss_functions.CrossEntropyLoss(classes=10, apply_softmax=False),\n",
    "        input_shape=(1, 28, 28, 1),\n",
    "        training_threshold=0.001\n",
    "    )\n",
    "    \n",
    "    ntk = production_model.compute_ntk(\n",
    "            data_subset,\n",
    "            normalize=False\n",
    "        )\n",
    "    entropy_empirical = rnd.analysis.EntropyAnalysis(\n",
    "        ntk[\"empirical\"]\n",
    "    ).compute_von_neumann_entropy(\n",
    "        normalize=False\n",
    "    )\n",
    "    \n",
    "    metrics_dict[str(item)] = {}\n",
    "    metrics_dict[str(item)][\"entropy\"] = [entropy_empirical]\n",
    "    \n",
    "    metrics = production_model.train_model(\n",
    "        train_ds = {\n",
    "            \"inputs\": data_generator.ds_train[\"image\"][:item],\n",
    "            \"targets\": data_generator.ds_train[\"label\"][:item]\n",
    "        }, \n",
    "        test_ds=test_ds, \n",
    "        batch_size=10, \n",
    "        epochs=200\n",
    "    )\n",
    "    ntk = production_model.compute_ntk(\n",
    "            data_subset,\n",
    "            normalize=True\n",
    "        )\n",
    "    entropy_empirical = rnd.analysis.EntropyAnalysis(\n",
    "        ntk[\"empirical\"]\n",
    "    ).compute_von_neumann_entropy(\n",
    "        normalize=False\n",
    "    )\n",
    "    \n",
    "    metrics_dict[str(item)][\"entropy\"].append(entropy_empirical)\n",
    "    metrics_dict[str(item)][\"model\"] = metrics\n",
    "    print(metrics_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170c9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
